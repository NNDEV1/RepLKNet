{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RepLKNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-q4CejOQ2kcy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "168c8307-f61d-4062-aab8-fbc4d8c3ea35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Transition                               --                        --\n",
              "├─Conv2d: 1-1                            [32, 3, 256, 256]         9\n",
              "├─DepthWiseConv2d: 1-2                   [32, 16, 128, 128]        --\n",
              "│    └─Conv2d: 2-1                       [32, 24, 256, 256]        216\n",
              "│    └─Conv2d: 2-2                       [32, 16, 128, 128]        384\n",
              "==========================================================================================\n",
              "Total params: 609\n",
              "Trainable params: 609\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 673.19\n",
              "==========================================================================================\n",
              "Input size (MB): 25.17\n",
              "Forward/backward pass size (MB): 520.09\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 545.26\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "from torchinfo import summary\n",
        "from timm.models.layers import DropPath\n",
        "\n",
        "class DepthWiseConv2d(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, c_out, kernels_per_layer, kernel_size, stride):\n",
        "        super(DepthWiseConv2d, self).__init__()\n",
        "\n",
        "        self.conv_dw = nn.Conv2d(c_in, c_in*kernels_per_layer, kernel_size=kernel_size, padding=1, groups=c_in, bias=False)\n",
        "        self.conv_pw = nn.Conv2d(c_in*kernels_per_layer, c_out, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return self.conv_pw(self.conv_dw(x))\n",
        "\n",
        "#dw_layer = DepthWiseConv2d(c_in=3, c_out=16, kernels_per_layer=8).cuda()\n",
        "\n",
        "#summary(dw_layer, (3, 256, 256), device=\"cuda\")\n",
        "\n",
        "class Stem(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, c_out):\n",
        "        super(Stem, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(c_in, c_out, kernel_size=3, stride=2, bias=False)\n",
        "        self.conv_dw1 = DepthWiseConv2d(c_out, c_out, kernels_per_layer=8, stride=1, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(c_out, c_out, kernel_size=1, padding=0, stride=1, bias=False)\n",
        "        self.conv_dw2 = DepthWiseConv2d(c_out, c_out, kernels_per_layer=8, stride=2, kernel_size=3)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv_dw1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv_dw2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Transition(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, c_out, kernels_per_layer, kernel_size):\n",
        "        super(Transition, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(c_in, c_in, kernel_size=1, stride=1, padding=\"same\", bias=False)\n",
        "        self.dw_conv = DepthWiseConv2d(c_in, c_out, kernels_per_layer, kernel_size, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.dw_conv(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "layer = Transition(c_in=3, c_out=16, kernels_per_layer=8, kernel_size=3).cuda()\n",
        "\n",
        "summary(layer, (32, 3, 256, 256))\n",
        "\n",
        "#layer = Stem(c_in=3, c_out=32).cuda()\n",
        "\n",
        "#summary(layer, (32, 3, 256, 256))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RepLKBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, kernel_size, c_in, c_out, prob):\n",
        "        super(RepLKBlock, self).__init__()\n",
        "        \n",
        "        #Only works for kernel sizes up to 9x9 5 1 7 2 9 3 11 4 13 5 15 6 17 7 19 8 21 9 23 10 25 11 27 12 29 13 31 14\n",
        "        if kernel_size <= 9:\n",
        "            padding = kernel_size // 3\n",
        "        elif kernel_size == 31:\n",
        "            padding = 14\n",
        "        elif kernel_size == 29:\n",
        "            padding = 13\n",
        "        elif kernel_size == 15:\n",
        "            padding = 6\n",
        "        \n",
        "\n",
        "        self.bn = nn.BatchNorm2d(c_in)\n",
        "        self.conv1 = nn.Conv2d(c_in, c_out, kernel_size=1, stride=1, bias=False)\n",
        "        self.conv_dw = DepthWiseConv2d(c_out, c_out, stride=1, kernels_per_layer=8, kernel_size=kernel_size)\n",
        "        self.conv2 = nn.Conv2d(c_out, c_out, kernel_size=1, stride=1, padding=padding, bias=False)\n",
        "        self.drop_path = DropPath(prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        add = x\n",
        "\n",
        "        x = self.bn(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv_dw(x)\n",
        "        x = self.conv2(x)\n",
        "\n",
        "        return self.drop_path(x) + add\n",
        "\n",
        "class ConvFFN(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, c_out, prob):\n",
        "        super(ConvFFN, self).__init__()\n",
        "\n",
        "        self.bn = nn.BatchNorm2d(c_in)\n",
        "        self.conv1 = nn.Conv2d(c_in, c_out, kernel_size=3, padding=\"same\", stride=1, bias=False)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.conv2 = nn.Conv2d(c_out, c_out, kernel_size=3, padding=\"same\", stride=1, bias=False)\n",
        "        self.drop_path = DropPath(prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        add = x\n",
        "\n",
        "        x = self.bn(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.conv2(x)\n",
        "\n",
        "        return self.drop_path(x) + add\n",
        "\n",
        "\n",
        "\n",
        "block = RepLKBlock(c_in=16, c_out=16, kernel_size=15, prob=0.2).cuda()\n",
        "\n",
        "summary(block, (32, 16, 256, 256), device=\"cuda\")\n",
        "\n",
        "#block = ConvFFN(c_in=16, c_out=16).cuda()\n",
        "\n",
        "#summary(block, (32, 16, 256, 256), device=\"cuda\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n_OYs7l6cdx",
        "outputId": "af8fd3ff-cf8d-417a-caf3-e1732754575e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "RepLKBlock                               --                        --\n",
              "├─BatchNorm2d: 1-1                       [32, 16, 256, 256]        32\n",
              "├─Conv2d: 1-2                            [32, 16, 256, 256]        256\n",
              "├─DepthWiseConv2d: 1-3                   [32, 16, 244, 244]        --\n",
              "│    └─Conv2d: 2-1                       [32, 128, 244, 244]       28,800\n",
              "│    └─Conv2d: 2-2                       [32, 16, 244, 244]        2,048\n",
              "├─Conv2d: 1-4                            [32, 16, 256, 256]        256\n",
              "├─DropPath: 1-5                          [32, 16, 256, 256]        --\n",
              "==========================================================================================\n",
              "Total params: 31,392\n",
              "Trainable params: 31,392\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 59.84\n",
              "==========================================================================================\n",
              "Input size (MB): 134.22\n",
              "Forward/backward pass size (MB): 3000.04\n",
              "Params size (MB): 0.13\n",
              "Estimated Total Size (MB): 3134.38\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stem\n",
        "# Stage 1: (RepLKBlock, ConvFFN, ..., RepLKBlock, ConvFFN)\n",
        "# Transition 1\n",
        "# Stage 2: (RepLKBlock, ConvFFN, ..., RepLKBlock, ConvFFN)\n",
        "# Transition 2\n",
        "# Stage 3: (RepLKBlock, ConvFFN, ..., RepLKBlock, ConvFFN)\n",
        "# Transition 3\n",
        "# Stage 4: (RepLKBlock, ConvFFN, ..., RepLKBlock, ConvFFN)\n",
        "# Transition 4\n",
        "\n",
        "class RepLKNet(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, num_classes, num_blocks_per_stage=3, prob=0.3, kernel_sizes=[31, 29, 15, 7]):\n",
        "        super(RepLKNet, self).__init__()\n",
        "\n",
        "        c_out = 32\n",
        "\n",
        "        self.stem = Stem(c_in, c_out)\n",
        "\n",
        "        modules1 = []\n",
        "\n",
        "        for i in range(num_blocks_per_stage):\n",
        "            modules1.append(RepLKBlock(kernel_sizes[0], c_out, c_out, prob=prob)) \n",
        "            modules1.append(ConvFFN(c_out, c_out, prob=prob))\n",
        "    \n",
        "        self.stage1 = nn.Sequential(*modules1)\n",
        "        self.transition1 = Transition(c_out, c_out*2, kernels_per_layer=8, kernel_size=3)\n",
        "        c_out = c_out*2\n",
        "\n",
        "        modules2 = []\n",
        "\n",
        "        for i in range(num_blocks_per_stage):\n",
        "            modules2.append(RepLKBlock(kernel_sizes[1], c_out, c_out, prob=prob)) \n",
        "            modules2.append(ConvFFN(c_out, c_out, prob=prob))\n",
        "\n",
        "        self.stage2 = nn.Sequential(*modules2)\n",
        "        self.transition2 = Transition(c_out, c_out*2, kernels_per_layer=16, kernel_size=3)\n",
        "        c_out = c_out*2\n",
        "\n",
        "        modules3 = []\n",
        "\n",
        "        for i in range(num_blocks_per_stage):\n",
        "            modules3.append(RepLKBlock(kernel_sizes[2], c_out, c_out, prob=prob)) \n",
        "            modules3.append(ConvFFN(c_out, c_out, prob=prob))\n",
        "\n",
        "        self.stage3 = nn.Sequential(*modules3)\n",
        "        self.transition3 = Transition(c_out, c_out*2, kernels_per_layer=32, kernel_size=3)\n",
        "        c_out = c_out*2\n",
        "\n",
        "        modules4 = []\n",
        "\n",
        "        for i in range(num_blocks_per_stage):\n",
        "            modules4.append(RepLKBlock(kernel_sizes[3], c_out, c_out, prob=prob)) \n",
        "            modules4.append(ConvFFN(c_out, c_out, prob=prob))\n",
        "\n",
        "        self.stage4 = nn.Sequential(*modules4)\n",
        "        self.transition4 = Transition(c_out, c_out*2, kernels_per_layer=64, kernel_size=3)\n",
        "        c_out = c_out*2\n",
        "\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.fc = nn.Sequential(*[nn.Linear(512, c_out//2),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.Linear(c_out//2, c_out//4),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.Linear(c_out//4, num_classes)])\n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.stem(x)\n",
        "        x = self.stage1(x)\n",
        "        x = self.transition1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.transition2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.transition3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = self.transition4(x)\n",
        "        x = self.adaptive_pool(x)\n",
        "        x = x.view((x.size(0), -1))\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = RepLKNet(3, 10).cuda()\n",
        "\n",
        "summary(model, (32, 3, 256, 256), kernel_sizes=[31, 29, 15, 7])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF-CmJXe9hA_",
        "outputId": "4382bcf6-4cdd-4aab-e891-37bd4156fdaa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "RepLKNet                                 --                        --\n",
              "├─Stem: 1-1                              [32, 32, 64, 64]          --\n",
              "│    └─Conv2d: 2-1                       [32, 32, 127, 127]        864\n",
              "│    └─DepthWiseConv2d: 2-2              [32, 32, 127, 127]        --\n",
              "│    │    └─Conv2d: 3-1                  [32, 256, 127, 127]       2,304\n",
              "│    │    └─Conv2d: 3-2                  [32, 32, 127, 127]        8,192\n",
              "│    └─Conv2d: 2-3                       [32, 32, 127, 127]        1,024\n",
              "│    └─DepthWiseConv2d: 2-4              [32, 32, 64, 64]          --\n",
              "│    │    └─Conv2d: 3-3                  [32, 256, 127, 127]       2,304\n",
              "│    │    └─Conv2d: 3-4                  [32, 32, 64, 64]          8,192\n",
              "├─Sequential: 1-2                        [32, 32, 64, 64]          --\n",
              "│    └─RepLKBlock: 2-5                   [32, 32, 64, 64]          --\n",
              "│    │    └─BatchNorm2d: 3-5             [32, 32, 64, 64]          64\n",
              "│    │    └─Conv2d: 3-6                  [32, 32, 64, 64]          1,024\n",
              "│    │    └─DepthWiseConv2d: 3-7         [32, 32, 36, 36]          254,208\n",
              "│    │    └─Conv2d: 3-8                  [32, 32, 64, 64]          1,024\n",
              "│    │    └─DropPath: 3-9                [32, 32, 64, 64]          --\n",
              "│    └─ConvFFN: 2-6                      [32, 32, 64, 64]          --\n",
              "│    │    └─BatchNorm2d: 3-10            [32, 32, 64, 64]          64\n",
              "│    │    └─Conv2d: 3-11                 [32, 32, 64, 64]          9,216\n",
              "│    │    └─GELU: 3-12                   [32, 32, 64, 64]          --\n",
              "│    │    └─Conv2d: 3-13                 [32, 32, 64, 64]          9,216\n",
              "│    │    └─DropPath: 3-14               [32, 32, 64, 64]          --\n",
              "│    └─RepLKBlock: 2-7                   [32, 32, 64, 64]          --\n",
              "│    │    └─BatchNorm2d: 3-15            [32, 32, 64, 64]          64\n",
              "│    │    └─Conv2d: 3-16                 [32, 32, 64, 64]          1,024\n",
              "│    │    └─DepthWiseConv2d: 3-17        [32, 32, 36, 36]          254,208\n",
              "│    │    └─Conv2d: 3-18                 [32, 32, 64, 64]          1,024\n",
              "│    │    └─DropPath: 3-19               [32, 32, 64, 64]          --\n",
              "│    └─ConvFFN: 2-8                      [32, 32, 64, 64]          --\n",
              "│    │    └─BatchNorm2d: 3-20            [32, 32, 64, 64]          64\n",
              "│    │    └─Conv2d: 3-21                 [32, 32, 64, 64]          9,216\n",
              "│    │    └─GELU: 3-22                   [32, 32, 64, 64]          --\n",
              "│    │    └─Conv2d: 3-23                 [32, 32, 64, 64]          9,216\n",
              "│    │    └─DropPath: 3-24               [32, 32, 64, 64]          --\n",
              "│    └─RepLKBlock: 2-9                   [32, 32, 64, 64]          --\n",
              "│    │    └─BatchNorm2d: 3-25            [32, 32, 64, 64]          64\n",
              "│    │    └─Conv2d: 3-26                 [32, 32, 64, 64]          1,024\n",
              "│    │    └─DepthWiseConv2d: 3-27        [32, 32, 36, 36]          254,208\n",
              "│    │    └─Conv2d: 3-28                 [32, 32, 64, 64]          1,024\n",
              "│    │    └─DropPath: 3-29               [32, 32, 64, 64]          --\n",
              "│    └─ConvFFN: 2-10                     [32, 32, 64, 64]          --\n",
              "│    │    └─BatchNorm2d: 3-30            [32, 32, 64, 64]          64\n",
              "│    │    └─Conv2d: 3-31                 [32, 32, 64, 64]          9,216\n",
              "│    │    └─GELU: 3-32                   [32, 32, 64, 64]          --\n",
              "│    │    └─Conv2d: 3-33                 [32, 32, 64, 64]          9,216\n",
              "│    │    └─DropPath: 3-34               [32, 32, 64, 64]          --\n",
              "├─Transition: 1-3                        [32, 64, 32, 32]          --\n",
              "│    └─Conv2d: 2-11                      [32, 32, 64, 64]          1,024\n",
              "│    └─DepthWiseConv2d: 2-12             [32, 64, 32, 32]          --\n",
              "│    │    └─Conv2d: 3-35                 [32, 256, 64, 64]         2,304\n",
              "│    │    └─Conv2d: 3-36                 [32, 64, 32, 32]          16,384\n",
              "├─Sequential: 1-4                        [32, 64, 32, 32]          --\n",
              "│    └─RepLKBlock: 2-13                  [32, 64, 32, 32]          --\n",
              "│    │    └─BatchNorm2d: 3-37            [32, 64, 32, 32]          128\n",
              "│    │    └─Conv2d: 3-38                 [32, 64, 32, 32]          4,096\n",
              "│    │    └─DepthWiseConv2d: 3-39        [32, 64, 6, 6]            463,360\n",
              "│    │    └─Conv2d: 3-40                 [32, 64, 32, 32]          4,096\n",
              "│    │    └─DropPath: 3-41               [32, 64, 32, 32]          --\n",
              "│    └─ConvFFN: 2-14                     [32, 64, 32, 32]          --\n",
              "│    │    └─BatchNorm2d: 3-42            [32, 64, 32, 32]          128\n",
              "│    │    └─Conv2d: 3-43                 [32, 64, 32, 32]          36,864\n",
              "│    │    └─GELU: 3-44                   [32, 64, 32, 32]          --\n",
              "│    │    └─Conv2d: 3-45                 [32, 64, 32, 32]          36,864\n",
              "│    │    └─DropPath: 3-46               [32, 64, 32, 32]          --\n",
              "│    └─RepLKBlock: 2-15                  [32, 64, 32, 32]          --\n",
              "│    │    └─BatchNorm2d: 3-47            [32, 64, 32, 32]          128\n",
              "│    │    └─Conv2d: 3-48                 [32, 64, 32, 32]          4,096\n",
              "│    │    └─DepthWiseConv2d: 3-49        [32, 64, 6, 6]            463,360\n",
              "│    │    └─Conv2d: 3-50                 [32, 64, 32, 32]          4,096\n",
              "│    │    └─DropPath: 3-51               [32, 64, 32, 32]          --\n",
              "│    └─ConvFFN: 2-16                     [32, 64, 32, 32]          --\n",
              "│    │    └─BatchNorm2d: 3-52            [32, 64, 32, 32]          128\n",
              "│    │    └─Conv2d: 3-53                 [32, 64, 32, 32]          36,864\n",
              "│    │    └─GELU: 3-54                   [32, 64, 32, 32]          --\n",
              "│    │    └─Conv2d: 3-55                 [32, 64, 32, 32]          36,864\n",
              "│    │    └─DropPath: 3-56               [32, 64, 32, 32]          --\n",
              "│    └─RepLKBlock: 2-17                  [32, 64, 32, 32]          --\n",
              "│    │    └─BatchNorm2d: 3-57            [32, 64, 32, 32]          128\n",
              "│    │    └─Conv2d: 3-58                 [32, 64, 32, 32]          4,096\n",
              "│    │    └─DepthWiseConv2d: 3-59        [32, 64, 6, 6]            463,360\n",
              "│    │    └─Conv2d: 3-60                 [32, 64, 32, 32]          4,096\n",
              "│    │    └─DropPath: 3-61               [32, 64, 32, 32]          --\n",
              "│    └─ConvFFN: 2-18                     [32, 64, 32, 32]          --\n",
              "│    │    └─BatchNorm2d: 3-62            [32, 64, 32, 32]          128\n",
              "│    │    └─Conv2d: 3-63                 [32, 64, 32, 32]          36,864\n",
              "│    │    └─GELU: 3-64                   [32, 64, 32, 32]          --\n",
              "│    │    └─Conv2d: 3-65                 [32, 64, 32, 32]          36,864\n",
              "│    │    └─DropPath: 3-66               [32, 64, 32, 32]          --\n",
              "├─Transition: 1-5                        [32, 128, 16, 16]         --\n",
              "│    └─Conv2d: 2-19                      [32, 64, 32, 32]          4,096\n",
              "│    └─DepthWiseConv2d: 2-20             [32, 128, 16, 16]         --\n",
              "│    │    └─Conv2d: 3-67                 [32, 1024, 32, 32]        9,216\n",
              "│    │    └─Conv2d: 3-68                 [32, 128, 16, 16]         131,072\n",
              "├─Sequential: 1-6                        [32, 128, 16, 16]         --\n",
              "│    └─RepLKBlock: 2-21                  [32, 128, 16, 16]         --\n",
              "│    │    └─BatchNorm2d: 3-69            [32, 128, 16, 16]         256\n",
              "│    │    └─Conv2d: 3-70                 [32, 128, 16, 16]         16,384\n",
              "│    │    └─DepthWiseConv2d: 3-71        [32, 128, 4, 4]           361,472\n",
              "│    │    └─Conv2d: 3-72                 [32, 128, 16, 16]         16,384\n",
              "│    │    └─DropPath: 3-73               [32, 128, 16, 16]         --\n",
              "│    └─ConvFFN: 2-22                     [32, 128, 16, 16]         --\n",
              "│    │    └─BatchNorm2d: 3-74            [32, 128, 16, 16]         256\n",
              "│    │    └─Conv2d: 3-75                 [32, 128, 16, 16]         147,456\n",
              "│    │    └─GELU: 3-76                   [32, 128, 16, 16]         --\n",
              "│    │    └─Conv2d: 3-77                 [32, 128, 16, 16]         147,456\n",
              "│    │    └─DropPath: 3-78               [32, 128, 16, 16]         --\n",
              "│    └─RepLKBlock: 2-23                  [32, 128, 16, 16]         --\n",
              "│    │    └─BatchNorm2d: 3-79            [32, 128, 16, 16]         256\n",
              "│    │    └─Conv2d: 3-80                 [32, 128, 16, 16]         16,384\n",
              "│    │    └─DepthWiseConv2d: 3-81        [32, 128, 4, 4]           361,472\n",
              "│    │    └─Conv2d: 3-82                 [32, 128, 16, 16]         16,384\n",
              "│    │    └─DropPath: 3-83               [32, 128, 16, 16]         --\n",
              "│    └─ConvFFN: 2-24                     [32, 128, 16, 16]         --\n",
              "│    │    └─BatchNorm2d: 3-84            [32, 128, 16, 16]         256\n",
              "│    │    └─Conv2d: 3-85                 [32, 128, 16, 16]         147,456\n",
              "│    │    └─GELU: 3-86                   [32, 128, 16, 16]         --\n",
              "│    │    └─Conv2d: 3-87                 [32, 128, 16, 16]         147,456\n",
              "│    │    └─DropPath: 3-88               [32, 128, 16, 16]         --\n",
              "│    └─RepLKBlock: 2-25                  [32, 128, 16, 16]         --\n",
              "│    │    └─BatchNorm2d: 3-89            [32, 128, 16, 16]         256\n",
              "│    │    └─Conv2d: 3-90                 [32, 128, 16, 16]         16,384\n",
              "│    │    └─DepthWiseConv2d: 3-91        [32, 128, 4, 4]           361,472\n",
              "│    │    └─Conv2d: 3-92                 [32, 128, 16, 16]         16,384\n",
              "│    │    └─DropPath: 3-93               [32, 128, 16, 16]         --\n",
              "│    └─ConvFFN: 2-26                     [32, 128, 16, 16]         --\n",
              "│    │    └─BatchNorm2d: 3-94            [32, 128, 16, 16]         256\n",
              "│    │    └─Conv2d: 3-95                 [32, 128, 16, 16]         147,456\n",
              "│    │    └─GELU: 3-96                   [32, 128, 16, 16]         --\n",
              "│    │    └─Conv2d: 3-97                 [32, 128, 16, 16]         147,456\n",
              "│    │    └─DropPath: 3-98               [32, 128, 16, 16]         --\n",
              "├─Transition: 1-7                        [32, 256, 8, 8]           --\n",
              "│    └─Conv2d: 2-27                      [32, 128, 16, 16]         16,384\n",
              "│    └─DepthWiseConv2d: 2-28             [32, 256, 8, 8]           --\n",
              "│    │    └─Conv2d: 3-99                 [32, 4096, 16, 16]        36,864\n",
              "│    │    └─Conv2d: 3-100                [32, 256, 8, 8]           1,048,576\n",
              "├─Sequential: 1-8                        [32, 256, 8, 8]           --\n",
              "│    └─RepLKBlock: 2-29                  [32, 256, 8, 8]           --\n",
              "│    │    └─BatchNorm2d: 3-101           [32, 256, 8, 8]           512\n",
              "│    │    └─Conv2d: 3-102                [32, 256, 8, 8]           65,536\n",
              "│    │    └─DepthWiseConv2d: 3-103       [32, 256, 4, 4]           624,640\n",
              "│    │    └─Conv2d: 3-104                [32, 256, 8, 8]           65,536\n",
              "│    │    └─DropPath: 3-105              [32, 256, 8, 8]           --\n",
              "│    └─ConvFFN: 2-30                     [32, 256, 8, 8]           --\n",
              "│    │    └─BatchNorm2d: 3-106           [32, 256, 8, 8]           512\n",
              "│    │    └─Conv2d: 3-107                [32, 256, 8, 8]           589,824\n",
              "│    │    └─GELU: 3-108                  [32, 256, 8, 8]           --\n",
              "│    │    └─Conv2d: 3-109                [32, 256, 8, 8]           589,824\n",
              "│    │    └─DropPath: 3-110              [32, 256, 8, 8]           --\n",
              "│    └─RepLKBlock: 2-31                  [32, 256, 8, 8]           --\n",
              "│    │    └─BatchNorm2d: 3-111           [32, 256, 8, 8]           512\n",
              "│    │    └─Conv2d: 3-112                [32, 256, 8, 8]           65,536\n",
              "│    │    └─DepthWiseConv2d: 3-113       [32, 256, 4, 4]           624,640\n",
              "│    │    └─Conv2d: 3-114                [32, 256, 8, 8]           65,536\n",
              "│    │    └─DropPath: 3-115              [32, 256, 8, 8]           --\n",
              "│    └─ConvFFN: 2-32                     [32, 256, 8, 8]           --\n",
              "│    │    └─BatchNorm2d: 3-116           [32, 256, 8, 8]           512\n",
              "│    │    └─Conv2d: 3-117                [32, 256, 8, 8]           589,824\n",
              "│    │    └─GELU: 3-118                  [32, 256, 8, 8]           --\n",
              "│    │    └─Conv2d: 3-119                [32, 256, 8, 8]           589,824\n",
              "│    │    └─DropPath: 3-120              [32, 256, 8, 8]           --\n",
              "│    └─RepLKBlock: 2-33                  [32, 256, 8, 8]           --\n",
              "│    │    └─BatchNorm2d: 3-121           [32, 256, 8, 8]           512\n",
              "│    │    └─Conv2d: 3-122                [32, 256, 8, 8]           65,536\n",
              "│    │    └─DepthWiseConv2d: 3-123       [32, 256, 4, 4]           624,640\n",
              "│    │    └─Conv2d: 3-124                [32, 256, 8, 8]           65,536\n",
              "│    │    └─DropPath: 3-125              [32, 256, 8, 8]           --\n",
              "│    └─ConvFFN: 2-34                     [32, 256, 8, 8]           --\n",
              "│    │    └─BatchNorm2d: 3-126           [32, 256, 8, 8]           512\n",
              "│    │    └─Conv2d: 3-127                [32, 256, 8, 8]           589,824\n",
              "│    │    └─GELU: 3-128                  [32, 256, 8, 8]           --\n",
              "│    │    └─Conv2d: 3-129                [32, 256, 8, 8]           589,824\n",
              "│    │    └─DropPath: 3-130              [32, 256, 8, 8]           --\n",
              "├─Transition: 1-9                        [32, 512, 4, 4]           --\n",
              "│    └─Conv2d: 2-35                      [32, 256, 8, 8]           65,536\n",
              "│    └─DepthWiseConv2d: 2-36             [32, 512, 4, 4]           --\n",
              "│    │    └─Conv2d: 3-131                [32, 16384, 8, 8]         147,456\n",
              "│    │    └─Conv2d: 3-132                [32, 512, 4, 4]           8,388,608\n",
              "├─AdaptiveAvgPool2d: 1-10                [32, 512, 1, 1]           --\n",
              "├─Sequential: 1-11                       [32, 10]                  --\n",
              "│    └─Linear: 2-37                      [32, 256]                 131,328\n",
              "│    └─ReLU: 2-38                        [32, 256]                 --\n",
              "│    └─Linear: 2-39                      [32, 128]                 32,896\n",
              "│    └─ReLU: 2-40                        [32, 128]                 --\n",
              "│    └─Linear: 2-41                      [32, 10]                  1,290\n",
              "==========================================================================================\n",
              "Total params: 20,395,114\n",
              "Trainable params: 20,395,114\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 85.41\n",
              "==========================================================================================\n",
              "Input size (MB): 25.17\n",
              "Forward/backward pass size (MB): 5189.72\n",
              "Params size (MB): 81.58\n",
              "Estimated Total Size (MB): 5296.47\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QvqIgJ1aLr3f"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}